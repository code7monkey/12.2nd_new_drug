{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNb6eVS6rQf7EaIbUQwKJbl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ㅇ"],"metadata":{"id":"diRmKtKVlxUD"}},{"cell_type":"code","source":["!pip install rdkit-pypi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8MrGNZHEhXYD","executionInfo":{"status":"ok","timestamp":1723783818225,"user_tz":-540,"elapsed":11862,"user":{"displayName":"이승현","userId":"09131068715081423692"}},"outputId":"b3bdc0e5-59d5-437b-8787-0dc82c9b0418"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rdkit-pypi\n","  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (1.26.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (9.4.0)\n","Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: rdkit-pypi\n","Successfully installed rdkit-pypi-2022.9.5\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dasnpj2Qfukh","executionInfo":{"status":"ok","timestamp":1723783787446,"user_tz":-540,"elapsed":18842,"user":{"displayName":"이승현","userId":"09131068715081423692"}},"outputId":"bc07d60b-71c6-492c-e87d-bf91e3610307"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","import random\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import KFold\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import LinearRegression\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import StackingRegressor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LwRHSQbff1mD","executionInfo":{"status":"ok","timestamp":1723786274898,"user_tz":-540,"elapsed":2333,"user":{"displayName":"이승현","userId":"09131068715081423692"}},"outputId":"626ad879-00fd-4927-cbce-3d096b986a89"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n"]}]},{"cell_type":"code","source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","\n","seed_everything(42) # Seed 고정"],"metadata":{"id":"ERdo-_PKf_zK","executionInfo":{"status":"ok","timestamp":1723786274899,"user_tz":-540,"elapsed":4,"user":{"displayName":"이승현","userId":"09131068715081423692"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["# 평가 산식 정의 (로그 변환 시 음수/0 방지)\n","def normalized_rmse(y_true, y_pred):\n","    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n","    normalized_rmse_value = rmse / np.mean(y_true)\n","    return normalized_rmse_value\n","\n","def correct_ratio(y_true, y_pred):\n","    # 0 또는 음수 값을 방지하기 위해 작은 양수로 대체\n","    y_true = np.where(y_true <= 0, 1e-9, y_true)\n","    y_pred = np.where(y_pred <= 0, 1e-9, y_pred)\n","\n","    pIC50_true = -np.log10(y_true * 1e-9)\n","    pIC50_pred = -np.log10(y_pred * 1e-9)\n","\n","    absolute_error = np.abs(pIC50_true - pIC50_pred)\n","    correct_ratio_value = np.mean(absolute_error <= 0.5)\n","    return correct_ratio_value\n","\n","def custom_score(y_true, y_pred):\n","    A = normalized_rmse(y_true, y_pred)\n","    B = correct_ratio(y_true, y_pred)\n","    score = 0.5 * (1 - min(A, 1)) + 0.5 * B\n","    return score\n"],"metadata":{"id":"mtuy8PGngBXL","executionInfo":{"status":"ok","timestamp":1723786274899,"user_tz":-540,"elapsed":3,"user":{"displayName":"이승현","userId":"09131068715081423692"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["from rdkit import Chem\n","from rdkit.Chem import AllChem\n","from rdkit.Chem import Descriptors\n","\n","# RDKit을 사용해 SMILES 문자열을 피처로 변환하는 함수\n","def featurize(smiles):\n","    mol = Chem.MolFromSmiles(smiles)\n","    if mol is None:\n","        return np.zeros(2048)  # 오류가 있을 경우 0 벡터 반환\n","    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n","    return np.array(fp)\n","\n","# 데이터 로드\n","train_df = pd.read_csv('/content/drive/MyDrive/신약개발/train.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/신약개발/test.csv')\n","\n","# 훈련 및 테스트 데이터에서 SMILES 피처 추출\n","train_df['smiles_features'] = train_df['Smiles'].apply(featurize)\n","test_df['smiles_features'] = test_df['Smiles'].apply(featurize)\n","\n","# SMILES 피처를 개별 컬럼으로 확장\n","X_train = np.vstack(train_df['smiles_features'])\n","X_test = np.vstack(test_df['smiles_features'])\n","y_train = train_df['IC50_nM'].values"],"metadata":{"id":"04atqtfcgywz","executionInfo":{"status":"ok","timestamp":1723786280373,"user_tz":-540,"elapsed":4671,"user":{"displayName":"이승현","userId":"09131068715081423692"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["# K-Fold 교차 검증 설정\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# 모델 초기화 및 평가\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# 1차 모델 정의 (개별 모델)\n","level0 = [\n","    ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),\n","    ('xgb', XGBRegressor(random_state=42)),\n","    ('lgbm', LGBMRegressor(random_state=42))\n","]\n","\n","# 2차 메타 모델 정의\n","level1 = LinearRegression()\n","\n","# 스태킹 모델 정의\n","stacking_model = StackingRegressor(estimators=level0, final_estimator=level1, cv=kf)\n","\n","# K-Fold 교차 검증을 통한 평가\n","best_score = float('-inf')\n","for train_index, val_index in kf.split(X_train_scaled):\n","    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n","    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n","\n","    stacking_model.fit(X_train_fold, y_train_fold)\n","\n","    val_predictions = stacking_model.predict(X_val_fold)\n","    score = custom_score(y_val_fold, val_predictions)\n","    if score > best_score:\n","        best_score = score\n","\n","print(f\"Best Model Score: {best_score}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hz_Hk8lSgNcy","executionInfo":{"status":"ok","timestamp":1723787398474,"user_tz":-540,"elapsed":1117294,"user":{"displayName":"이승현","userId":"09131068715081423692"}},"outputId":"af5ae06f-cad3-4e2d-fa44-d9e41c3e3ec9"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009053 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1830\n","[LightGBM] [Info] Number of data points in the train set: 1561, number of used features: 610\n","[LightGBM] [Info] Start training from score 650.147773\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008843 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1614\n","[LightGBM] [Info] Number of data points in the train set: 1248, number of used features: 538\n","[LightGBM] [Info] Start training from score 685.935326\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009148 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1623\n","[LightGBM] [Info] Number of data points in the train set: 1249, number of used features: 541\n","[LightGBM] [Info] Start training from score 630.023029\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009740 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1617\n","[LightGBM] [Info] Number of data points in the train set: 1249, number of used features: 539\n","[LightGBM] [Info] Start training from score 683.047393\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009234 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1629\n","[LightGBM] [Info] Number of data points in the train set: 1249, number of used features: 543\n","[LightGBM] [Info] Start training from score 594.323396\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011409 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1641\n","[LightGBM] [Info] Number of data points in the train set: 1249, number of used features: 547\n","[LightGBM] [Info] Start training from score 657.438372\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008537 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1839\n","[LightGBM] [Info] Number of data points in the train set: 1561, number of used features: 613\n","[LightGBM] [Info] Start training from score 625.378012\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006138 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1611\n","[LightGBM] [Info] Number of data points in the train set: 1248, number of used features: 537\n","[LightGBM] [Info] Start training from score 661.081640\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006157 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1617\n","[LightGBM] [Info] Number of data points in the train set: 1249, number of used features: 539\n","[LightGBM] [Info] Start training from score 612.414135\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006271 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1608\n","[LightGBM] [Info] Number of data points in the train set: 1249, number of used features: 536\n","[LightGBM] [Info] Start training from score 659.489060\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006626 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1620\n","[LightGBM] [Info] Number of data points in the train set: 1249, number of used features: 540\n","[LightGBM] [Info] Start training from score 566.018826\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006330 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1659\n","[LightGBM] [Info] Number of data points in the train set: 1249, number of used features: 553\n","[LightGBM] [Info] Start training from score 627.914982\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008437 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1848\n","[LightGBM] [Info] Number of data points in the train set: 1562, number of used features: 616\n","[LightGBM] [Info] Start training from score 689.878727\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006965 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1605\n","[LightGBM] [Info] Number of data points in the train set: 1249, number of used features: 535\n","[LightGBM] [Info] Start training from score 690.251762\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007575 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1581\n","[LightGBM] [Info] Number of data points in the train set: 1249, number of used features: 527\n","[LightGBM] [Info] Start training from score 655.565172\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006109 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1566\n","[LightGBM] [Info] Number of data points in the train set: 1250, number of used features: 522\n","[LightGBM] [Info] Start training from score 731.947346\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006084 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1593\n","[LightGBM] [Info] Number of data points in the train set: 1250, number of used features: 531\n","[LightGBM] [Info] Start training from score 682.912815\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006172 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1581\n","[LightGBM] [Info] Number of data points in the train set: 1250, number of used features: 527\n","[LightGBM] [Info] Start training from score 688.689387\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008723 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1836\n","[LightGBM] [Info] Number of data points in the train set: 1562, number of used features: 612\n","[LightGBM] [Info] Start training from score 609.123684\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007374 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1605\n","[LightGBM] [Info] Number of data points in the train set: 1249, number of used features: 535\n","[LightGBM] [Info] Start training from score 612.755248\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006217 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1611\n","[LightGBM] [Info] Number of data points in the train set: 1249, number of used features: 537\n","[LightGBM] [Info] Start training from score 580.312129\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009125 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1614\n","[LightGBM] [Info] Number of data points in the train set: 1250, number of used features: 538\n","[LightGBM] [Info] Start training from score 639.902988\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006139 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1605\n","[LightGBM] [Info] Number of data points in the train set: 1250, number of used features: 535\n","[LightGBM] [Info] Start training from score 613.085666\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006089 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1581\n","[LightGBM] [Info] Number of data points in the train set: 1250, number of used features: 527\n","[LightGBM] [Info] Start training from score 599.542247\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008544 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1842\n","[LightGBM] [Info] Number of data points in the train set: 1562, number of used features: 614\n","[LightGBM] [Info] Start training from score 670.464239\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006130 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1596\n","[LightGBM] [Info] Number of data points in the train set: 1249, number of used features: 532\n","[LightGBM] [Info] Start training from score 672.848992\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006202 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1605\n","[LightGBM] [Info] Number of data points in the train set: 1249, number of used features: 535\n","[LightGBM] [Info] Start training from score 636.569921\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006186 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1617\n","[LightGBM] [Info] Number of data points in the train set: 1250, number of used features: 539\n","[LightGBM] [Info] Start training from score 711.355120\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006063 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1587\n","[LightGBM] [Info] Number of data points in the train set: 1250, number of used features: 529\n","[LightGBM] [Info] Start training from score 662.311151\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006374 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1629\n","[LightGBM] [Info] Number of data points in the train set: 1250, number of used features: 543\n","[LightGBM] [Info] Start training from score 669.210802\n","Best Model Score: 0.12692307692307692\n"]}]},{"cell_type":"code","source":["# 전체 데이터로 최종 모델 학습 및 테스트 데이터 예측\n","stacking_model.fit(X_train_scaled, y_train)\n","test_predictions = stacking_model.predict(X_test_scaled)\n","\n","# 결과 저장\n","submission_df = pd.DataFrame({\n","    'ID': test_df['ID'],\n","    'IC50_nM': test_predictions\n","})\n","submission_df.to_csv('stacking_submission.csv', index=False)\n","\n","from google.colab import files\n","files.download('stacking_submission.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":675},"id":"OzMz9eSrnDRe","executionInfo":{"status":"ok","timestamp":1723787735643,"user_tz":-540,"elapsed":292506,"user":{"displayName":"이승현","userId":"09131068715081423692"}},"outputId":"ea5c8df2-ffce-488c-dc9b-97f7c78547ff"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018116 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 2118\n","[LightGBM] [Info] Number of data points in the train set: 1952, number of used features: 706\n","[LightGBM] [Info] Start training from score 649.001365\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010620 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1830\n","[LightGBM] [Info] Number of data points in the train set: 1561, number of used features: 610\n","[LightGBM] [Info] Start training from score 650.147773\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008495 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1839\n","[LightGBM] [Info] Number of data points in the train set: 1561, number of used features: 613\n","[LightGBM] [Info] Start training from score 625.378012\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013057 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1848\n","[LightGBM] [Info] Number of data points in the train set: 1562, number of used features: 616\n","[LightGBM] [Info] Start training from score 689.878727\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013074 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1836\n","[LightGBM] [Info] Number of data points in the train set: 1562, number of used features: 612\n","[LightGBM] [Info] Start training from score 609.123684\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012713 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1842\n","[LightGBM] [Info] Number of data points in the train set: 1562, number of used features: 614\n","[LightGBM] [Info] Start training from score 670.464239\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_22176d78-b451-4e65-8a9e-3870506369e2\", \"stacking_submission.csv\", 3099)"]},"metadata":{}}]}]}